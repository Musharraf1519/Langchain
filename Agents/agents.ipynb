{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40c9f9cc",
   "metadata": {},
   "source": [
    "# To-Do List Manager Agent\n",
    "\n",
    "    Let's Build the To-Do List Manager Agent using logic and custom tools (file manipulation), but we'll clearly segment the code and explanation for each part, starting from scratch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4f632b",
   "metadata": {},
   "source": [
    "**1. Brain (LLM) üß†**<br>\n",
    "The Brain is the Large Language Model (LLM) that handles the reasoning. It takes the user's request and decides the best course of action: which tool to use, the exact arguments for that tool, or if the question can be answered directly.\n",
    "\n",
    "| Part          |Role in To-Do Agent                                                                                    |\n",
    "|---------------|-------------------------------------------------------------------------------------------------------|\n",
    "| Brain (LLM)   |Decides if the user wants to Add_Item, View_List, or Clear_List based on their natural language input. |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7f3aaf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Brain (LLM) initialized using gpt-3.5-turbo.\n"
     ]
    }
   ],
   "source": [
    "# üíª Code: Brain Setup\n",
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Set your API key environment variable (e.g., in your terminal or IDE)\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"YOUR_API_KEY_HERE\"\n",
    "\n",
    "# Initialize the LLM (The Brain)\n",
    "# Setting temperature to 0 makes the model deterministic and reliable for tool use\n",
    "llm_brain = ChatOpenAI(temperature=0, model=\"gpt-3.5-turbo\")\n",
    "\n",
    "print(\"‚úÖ Brain (LLM) initialized using gpt-3.5-turbo.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9473d4",
   "metadata": {},
   "source": [
    "**2. Tools üõ†Ô∏è**<br>\n",
    "Tools are the external functions the agent can call. Since LLMs can't directly read/write files or manage persistent state, we create three custom Python functions and wrap them so the LLM can use them.\n",
    "\n",
    "|Part\t|Tool Name\t|Function|\n",
    "|-------|-----------|--------|\n",
    "|Tools\t|Add_Item\t|Appends a task to the todo_list.txt file.|\n",
    "|Tools\t|View_List\t|Reads and returns the entire content of the todo_list.txt file.|\n",
    "|Tools\t|Clear_List\t|Empties the todo_list.txt file.|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da48318a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ 3 Tools defined and wrapped for file: todo_list.txt\n"
     ]
    }
   ],
   "source": [
    "# üíª Code: Tools Setup\n",
    "from langchain.agents import Tool\n",
    "\n",
    "TODO_FILE = \"todo_list.txt\"\n",
    "\n",
    "def add_to_list(item: str) -> str:\n",
    "    \"\"\"Adds a new single task/item to the to-do list file.\"\"\"\n",
    "    try:\n",
    "        with open(TODO_FILE, \"a\") as f:\n",
    "            f.write(item + \"\\n\")\n",
    "        return f\"Successfully added '{item}' to the to-do list.\"\n",
    "    except Exception as e:\n",
    "        return f\"Error adding item: {e}\"\n",
    "\n",
    "def view_list(query: str) -> str:\n",
    "    \"\"\"Reads and returns the current items in the todo list file.\"\"\"\n",
    "    try:\n",
    "        if not os.path.exists(TODO_FILE) or os.path.getsize(TODO_FILE) == 0:\n",
    "            return \"The to-do list is currently empty.\"\n",
    "        \n",
    "        with open(TODO_FILE, \"r\") as f:\n",
    "            content = f.read()\n",
    "        return \"Current To-Do List:\\n\" + content\n",
    "    except Exception as e:\n",
    "        return f\"Error viewing list: {e}\"\n",
    "\n",
    "def clear_list(query: str) -> str:\n",
    "    \"\"\"Empties the entire contents of the todo list file.\"\"\"\n",
    "    try:\n",
    "        with open(TODO_FILE, \"w\") as f:\n",
    "            f.write(\"\")\n",
    "        return \"To-do list cleared successfully.\"\n",
    "    except Exception as e:\n",
    "        return f\"Error clearing list: {e}\"\n",
    "\n",
    "# List of Tools for the Agent\n",
    "agent_tools = [\n",
    "    Tool(\n",
    "        name=\"Add_Item\",\n",
    "        func=add_to_list,\n",
    "        description=\"Useful for adding a new task to the to-do list. Input must be the exact task string.\"\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"View_List\",\n",
    "        func=view_list,\n",
    "        description=\"Useful for showing all current tasks in the list. Input is a placeholder and is ignored.\"\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"Clear_List\",\n",
    "        func=clear_list,\n",
    "        description=\"Useful for deleting all tasks from the list. Input is a placeholder and is ignored.\"\n",
    "    ),\n",
    "]\n",
    "\n",
    "print(f\"‚úÖ {len(agent_tools)} Tools defined and wrapped for file: {TODO_FILE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad866f4",
   "metadata": {},
   "source": [
    "**3. Instructions (Prompt) üìú**<br>\n",
    "The Instructions define the agent's identity, rules, and the expected thought process (the ReAct format). We use a System Message to inject the persona and constraints into the LLM's initial context.\n",
    "\n",
    "|Part\t|Purpose|\n",
    "|-------|-------|\n",
    "|Instructions\t|Sets the persona as a \"diligent and helpful To-Do List Manager\". Explicitly tells the agent to only use the provided tools for managing the list.|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6011ff8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Instructions (Prompt Template) customized with Agent Persona.\n"
     ]
    }
   ],
   "source": [
    "# üíª Code: Instructions Setup\n",
    "from langchain import hub\n",
    "\n",
    "# Define the System Message (Instructions)\n",
    "SYSTEM_MESSAGE = (\n",
    "    \"You are a diligent and helpful To-Do List Manager Agent. \"\n",
    "    \"Your primary goal is to use the provided tools to manage the user's to-do list stored in the file named 'todo_list.txt'. \"\n",
    "    \"Use the tools when the user's intent is clearly to add, view, or clear the list. \"\n",
    "    \"Be polite and confirm every action with the user.\"\n",
    ")\n",
    "\n",
    "# Pull the standard ReAct template from the LangChain hub\n",
    "prompt_template = hub.pull(\"hwchase17/react\")\n",
    "\n",
    "# Customize the template by injecting the System Message\n",
    "custom_prompt = prompt_template.partial(system_prompt=SYSTEM_MESSAGE)\n",
    "\n",
    "print(\"‚úÖ Instructions (Prompt Template) customized with Agent Persona.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa2ef19b",
   "metadata": {},
   "source": [
    "**4. Executor (Controller) üïπÔ∏è**<br>\n",
    "The Executor is the engine that runs the entire agent loop. It takes the Brain, Tools, and Instructions, and manages the cyclical flow: LLM's Thought ‚Üí Action ‚Üí Tool Observation ‚Üí back to the LLM.\n",
    "\n",
    "|Part|\tRole in To-Do Agent|\n",
    "|----|---------------------|\n",
    "|Executor (Controller)|\tCombines the LLM and Tools into an executable ReAct chain, managing the file I/O operations and response generation.|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3921dd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Executor (Controller) created and linked to the Brain, Tools, and Instructions.\n"
     ]
    }
   ],
   "source": [
    "# üíª Code: Executor Setup\n",
    "\n",
    "from langchain.agents import create_react_agent, AgentExecutor\n",
    "\n",
    "# Create the Agent Chain (The core logic/Agent Type)\n",
    "todo_agent = create_react_agent(\n",
    "    llm=llm_brain,\n",
    "    tools=agent_tools,\n",
    "    prompt=custom_prompt # Use our customized prompt\n",
    ")\n",
    "\n",
    "# Create the Executor (The Controller that runs the loop)\n",
    "agent_executor = AgentExecutor(\n",
    "    agent=todo_agent,\n",
    "    tools=agent_tools,\n",
    "    verbose=True, # Display the full Thought/Action/Observation loop\n",
    "    handle_parsing_errors=True\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Executor (Controller) created and linked to the Brain, Tools, and Instructions.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12368616",
   "metadata": {},
   "source": [
    "**5. Memory üß† (Optional)**<br>\n",
    "Memory allows the agent to maintain context across multiple turns. Since the To-Do List Agent uses a file (todo_list.txt) to maintain state (what items are on the list), that file acts as its long-term task memory.\n",
    "\n",
    "For conversational memory (remembering what was just said), we use a memory buffer. This is essential for handling follow-up questions or references.\n",
    "\n",
    "|Part\t|Purpose in To-Do Agent|\n",
    "|-------|----------------------|\n",
    "|Task Memory\t|The todo_list.txt file provides state persistence (which tasks are active).|\n",
    "Conversational Memory\t|A ConversationBufferWindowMemory allows the agent to reference previous turns (e.g., \"Add that to the list\" after naming an item).|\n",
    "\n",
    "<br><br>\n",
    "To fully integrate memory into a ReAct agent, we need to adjust the prompt to accept the history. For simplicity here, we define the memory object and then show how it would be used if the agent's prompt were specifically designed for chat history.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dfc479d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üíª Code: Memory Setup (Conversational)\n",
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "\n",
    "# Initialize Conversational Memory\n",
    "# We'll keep a memory of the last 5 exchanges (user input + agent output)\n",
    "agent_memory = ConversationBufferWindowMemory(\n",
    "    memory_key=\"chat_history\", \n",
    "    k=5, \n",
    "    return_messages=True \n",
    ")\n",
    "\n",
    "print(\"‚úÖ Conversational Memory initialized (Buffer Window, k=5).\")\n",
    "\n",
    "# --- Agent Execution Demonstration ---\n",
    "# Note: For this specific ReAct Agent setup, direct Memory integration into \n",
    "# the AgentExecutor often requires a different prompt or method.\n",
    "# For demo purposes, we will continue to use the simplified Executor.\n",
    "\n",
    "print(\"\\n--- To-Do List Agent Demo (Testing all parts) ---\")\n",
    "\n",
    "# Test 1: Add item\n",
    "print(\"\\n--- 1. User Input: Add an item ---\")\n",
    "response_add = agent_executor.invoke({\"input\": \"I need to add 'Call the plumber' to my list.\"})\n",
    "print(f\"\\n**Agent Final Response:** {response_add['output']}\")\n",
    "\n",
    "# Test 2: View list\n",
    "print(\"\\n--- 2. User Input: View the list ---\")\n",
    "response_view = agent_executor.invoke({\"input\": \"What do I have on my to-do list?\"})\n",
    "print(f\"\\n**Agent Final Response:** {response_view['output']}\")\n",
    "\n",
    "# Test 3: Clear list\n",
    "print(\"\\n--- 3. User Input: Clear the list ---\")\n",
    "response_clear = agent_executor.invoke({\"input\": \"Please wipe the list clean.\"})\n",
    "print(f\"\\n**Agent Final Response:** {response_clear['output']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
